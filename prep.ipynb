{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from gensim.similarities import MatrixSimilarity\n",
    "from TurkishStemmer import TurkishStemmer\n",
    "from gensim import corpora\n",
    "\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import pprint\n",
    "import string\n",
    "import spacy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBERS = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "\n",
    "pd.options.display.max_rows = 9999\n",
    "pd.options.display.max_columns = 9999\n",
    "spacy_nlp = spacy.blank('tr')\n",
    "stop_words = list(spacy_nlp.Defaults.stop_words)\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "punctuations = string.punctuation\n",
    "stemmer = TurkishStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter(query):\n",
    "  # Remove puncuations\n",
    "  query = re.sub(r'[^\\w\\s]',' ',query)\n",
    "\n",
    "  # Remove extra spaces\n",
    "  query = re.sub(' +',' ',query)\n",
    "\n",
    "  # Get tokens\n",
    "  tokens = spacy_nlp(query)\n",
    "\n",
    "  # Lower, strip and lemmatize\n",
    "  tokens = [word.text.lower().strip() for word in tokens]\n",
    "\n",
    "\n",
    "  # Remove stopwords, and exclude words less than 2 characters\n",
    "  tokens = [ word for word in tokens if \n",
    "            (word not in stop_words) and \n",
    "            (word not in punctuations) and \n",
    "            (word in NUMBERS or len(word) >= 2) and \n",
    "            (word != \"yok\") and\n",
    "            (word != \"nan\")]\n",
    "\n",
    "  # Stem tokens - Does not works well :(\n",
    "  # tokens = [stemmer.stem(word) for word in tokens]\n",
    "\n",
    "  return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_detector(df, percentage):\n",
    "  nans = df.isna().sum()\n",
    "  maxm = len(df)*percentage\n",
    "  result = []\n",
    "  for j, val in enumerate(nans):\n",
    "    if val > maxm:\n",
    "      result.append(nans.keys()[j])\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_value_analysis(df, minm):\n",
    "  uniques = df.nunique()\n",
    "  result = []\n",
    "  for j, val in enumerate(uniques):\n",
    "    if val < minm:\n",
    "      result.append(uniques.keys()[j])\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sepereate_num_cat(df):\n",
    "  categorical = []\n",
    "  numerical = []\n",
    "  for feature in df.columns:\n",
    "    if df[feature].dtype == object:\n",
    "      categorical.append(feature)\n",
    "    else:\n",
    "      numerical.append(feature)\n",
    "  return categorical, numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226263, 31)"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read DataFrame and convert all columnst to object type since we are dealing with NLP\n",
    "df = pd.read_excel(\"./dataset/ebebek.xlsx\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['STOK_ADI',\n",
       "  'ANA_KATEGORI_ADI',\n",
       "  'WEB_ANA_KATEGORI_TANIMI',\n",
       "  'KATEGORI_ADI',\n",
       "  'ALT_KATEGORI_ADI',\n",
       "  'MARKA_ADI',\n",
       "  'RENK_ADI',\n",
       "  'BEDEN',\n",
       "  'TEKSTIL_URUN_GRUBU_ADI',\n",
       "  'TEKSTIL_ADET_ADI',\n",
       "  'TEKSTIL_KOL_TIPI',\n",
       "  'TEKSTIL_KOL_TIPI_TANIMI',\n",
       "  'TEKSTIL_PACA_TIPI',\n",
       "  'TEKSTIL_PACA_TIPI_TANIMI',\n",
       "  'TEKSTIL_YAKA_TIPI_TANIMI',\n",
       "  'WEB_UZUN_ACIKLAMA',\n",
       "  'WEB_KISA_ACIKLAMA',\n",
       "  'META_KEY_ACIKLAMA',\n",
       "  'TEKNIK_SERVIS_ACIKLAMA',\n",
       "  'MALZEME_UZUN_ACIKLAMA',\n",
       "  'ASKI_DURUMU',\n",
       "  'EN_MALZEME_UZUN_ACIKLAMA',\n",
       "  'EN_STOK_ADI',\n",
       "  'REYON_TANIM',\n",
       "  'ANALIZ_KATEGORISI',\n",
       "  'WEB_BIRINCI_KATEGORI_TANIMI',\n",
       "  'WEB_IKINCI_KATEGORI_TANIMI',\n",
       "  'WEB_UCUNCU_KATEGORI_TANIMI',\n",
       "  'MAGAZA_KONUMU'],\n",
       " ['TEKSTIL_CINSIYET', 'TEKSTIL_YAKA_TIPI'])"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sepereate_num_cat(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TEKSTIL_KOL_TIPI',\n",
       " 'TEKSTIL_KOL_TIPI_TANIMI',\n",
       " 'TEKSTIL_PACA_TIPI',\n",
       " 'TEKSTIL_PACA_TIPI_TANIMI',\n",
       " 'TEKSTIL_YAKA_TIPI',\n",
       " 'TEKSTIL_YAKA_TIPI_TANIMI',\n",
       " 'WEB_KISA_ACIKLAMA',\n",
       " 'META_KEY_ACIKLAMA',\n",
       " 'TEKNIK_SERVIS_ACIKLAMA',\n",
       " 'EN_MALZEME_UZUN_ACIKLAMA',\n",
       " 'REYON_TANIM']"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find columns that includes more than %50 NaN values\n",
    "nan_detector(df, .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'TEKSTIL_CINSIYET'\n",
      "1045.0    81928\n",
      "1044.0    76609\n",
      "1046.0    43182\n",
      "1049.0     4689\n",
      "1047.0      249\n",
      "1048.0        1\n",
      "Name: TEKSTIL_CINSIYET, dtype: int64\n",
      "'TEKSTIL_KOL_TIPI'\n",
      "931    42797\n",
      "930    31438\n",
      "928    11197\n",
      "929     3450\n",
      "#YO      468\n",
      "934        5\n",
      "Name: TEKSTIL_KOL_TIPI, dtype: int64\n",
      "'TEKSTIL_KOL_TIPI_TANIMI'\n",
      "Uzun Kol     42797\n",
      "Kısa Kol     31438\n",
      "Atlet        11197\n",
      "İp Askılı     3450\n",
      "Name: TEKSTIL_KOL_TIPI_TANIMI, dtype: int64\n",
      "'TEKSTIL_YAKA_TIPI'\n",
      "1199.0    35697\n",
      "1200.0    10483\n",
      "1204.0     6144\n",
      "1202.0     5929\n",
      "1198.0     5605\n",
      "1201.0     2202\n",
      "1206.0     1602\n",
      "1203.0     1320\n",
      "1205.0      624\n",
      "Name: TEKSTIL_YAKA_TIPI, dtype: int64\n",
      "'TEKSTIL_YAKA_TIPI_TANIMI'\n",
      "Bisiklet Yaka    35697\n",
      "Çıtçıtlı Yaka    10483\n",
      "Modelli Yaka      6144\n",
      "Zarf Yaka         5929\n",
      "Bebe Yaka         5605\n",
      "Polo Yaka         2202\n",
      "V Yaka            1602\n",
      "Hakim Yaka        1320\n",
      "Fırfırlı Yaka      624\n",
      "Name: TEKSTIL_YAKA_TIPI_TANIMI, dtype: int64\n",
      "'WEB_UZUN_ACIKLAMA'\n",
      "X    140781\n",
      "Name: WEB_UZUN_ACIKLAMA, dtype: int64\n",
      "'WEB_KISA_ACIKLAMA'\n",
      "X    10673\n",
      "Name: WEB_KISA_ACIKLAMA, dtype: int64\n",
      "'META_KEY_ACIKLAMA'\n",
      "X    47239\n",
      "Name: META_KEY_ACIKLAMA, dtype: int64\n",
      "'TEKNIK_SERVIS_ACIKLAMA'\n",
      "X    1645\n",
      "Name: TEKNIK_SERVIS_ACIKLAMA, dtype: int64\n",
      "'MAGAZA_KONUMU'\n",
      "Masa              86539\n",
      "Bebek Giyim       79808\n",
      "Diğer             24260\n",
      "Ayakkabı          15023\n",
      "Çorap             10814\n",
      "Giyim Aksesuar     5716\n",
      "Gondol             2150\n",
      "Ev tekstili        1951\n",
      "Name: MAGAZA_KONUMU, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "uniques = unique_value_analysis(df, 10)\n",
    "for key in uniques:\n",
    "  pp.pprint(key)\n",
    "  pp.pprint(df[key].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEKSTIL_KOL_TIPI and TEKSTIL_YAKA_TIPI will be dropped. Since they are numerical. <br>\n",
    "WEB_UZUN_ACIKLAMA, WEB_KISA_ACIKLAMA, META_KEY_ACIKLAMA, TEKNIK_SERVIS_ACIKLAMA will be dropped since they only consist of 'X' values.<br>\n",
    "CINSIYET will be replaced by the following,<br>\n",
    "1044 -> Unisex \n",
    "1045 -> Kız \n",
    "1046 -> Erkek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped = [\n",
    " 'TEKSTIL_KOL_TIPI',\n",
    " 'TEKSTIL_KOL_TIPI_TANIMI',\n",
    " 'TEKSTIL_PACA_TIPI',\n",
    " 'TEKSTIL_PACA_TIPI_TANIMI',\n",
    " 'TEKSTIL_YAKA_TIPI',\n",
    " 'TEKSTIL_YAKA_TIPI_TANIMI',\n",
    " 'WEB_KISA_ACIKLAMA',\n",
    " 'META_KEY_ACIKLAMA',\n",
    " 'TEKNIK_SERVIS_ACIKLAMA',\n",
    " 'EN_MALZEME_UZUN_ACIKLAMA',\n",
    " 'REYON_TANIM',\n",
    " 'TEKSTIL_KOL_TIPI',\n",
    " 'TEKSTIL_YAKA_TIPI',\n",
    " 'WEB_UZUN_ACIKLAMA',\n",
    " 'WEB_KISA_ACIKLAMA',\n",
    " 'META_KEY_ACIKLAMA',\n",
    " 'TEKNIK_SERVIS_ACIKLAMA'\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226263, 19)"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unnecessary columns\n",
    "df.drop(dropped, axis=1, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert CINSIYET columns to object\n",
    "df[\"TEKSTIL_CINSIYET\"] = df[\"TEKSTIL_CINSIYET\"].replace([1044, 1045, 1046], [\"unisex\", \"kız\", \"erkek\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert every column to string since we are dealing with NLP task\n",
    "df.fillna(\"yok\", inplace=True)\n",
    "for feature in df.columns:\n",
    "  df[feature] = df[feature].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, feature in enumerate(df.columns):\n",
    "  if not j:\n",
    "    df[\"final_tokenized\"] = df[feature].map(lambda x: filter(x))\n",
    "  else:\n",
    "    df[\"final_tokenized\"] += df[feature].map(lambda x: filter(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = df[\"final_tokenized\"]\n",
    "\n",
    "#creating term dictionary\n",
    "dictionary = corpora.Dictionary(keywords)\n",
    "dictionary.save(\"./models/dictionary\")\n",
    "\n",
    "# creating corpus\n",
    "corpus = [dictionary.doc2bow(desc) for desc in keywords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary {\n",
      "          'boy': 0\n",
      "          'büyük': 1\n",
      "          'ebebek': 2\n",
      "          'hazır': 3\n",
      "          'hediye': 4\n",
      "          'malzemeler': 5\n",
      "          'masa': 6\n",
      "          'paketi': 7\n",
      "          'sarf': 8\n",
      "          '040mm': 9\n",
      "          '075mm': 10\n",
      "          '75x100': 11\n",
      "          'baskisiz': 12\n",
      "          'baskılı': 13\n",
      "          'bebek': 14\n",
      "          'cm': 15\n",
      "          'eco': 16\n",
      "          'eti̇ket': 17\n",
      "          'termal': 18\n",
      "          'şeffaf': 19\n",
      "          'ana': 20\n",
      "          'araç': 21\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Dictionary {\")\n",
    "for i, value in enumerate(dictionary):\n",
    "  print(f\"          '{dictionary[value]}': {value}\")\n",
    "  if i > 20:\n",
    "    break\n",
    "print(\"}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************* 0 *************************\n",
      "document: ['hazır', 'büyük', 'boy', 'hediye', 'paketi', 'sarf', 'malzemeler', 'ebebek', 'hazır', 'büyük', 'boy', 'hediye', 'paketi', 'sarf', 'malzemeler', 'masa']\n",
      "corpus: [(0, 2), (1, 2), (2, 1), (3, 2), (4, 2), (5, 2), (6, 1), (7, 2), (8, 2)]\n",
      "************************* 1 *************************\n",
      "document: ['075mm', '040mm', 'eco', 'termal', 'baskisiz', 'eti̇ket', 'sarf', 'malzemeler', 'sarf', 'malzemeler', 'sarf', 'malzemeler', 'sarf', 'malzemeler', 'bebek', '075mm', '040mm', 'eco', 'termal', 'baskisiz', 'eti̇ket', 'şeffaf', 'ebebek', 'baskılı', '75x100', 'cm', 'sarf', 'malzemeler', 'sarf', 'malzemeler', 'sarf', 'malzemeler']\n",
      "corpus: [(2, 1), (5, 7), (8, 7), (9, 2), (10, 2), (11, 1), (12, 2), (13, 1), (14, 1), (15, 1), (16, 2), (17, 2), (18, 2), (19, 1)]\n",
      "************************* 2 *************************\n",
      "document: ['075mm', '075mm', 'eco', 'termal', 'baskisiz', 'eti̇ket', 'sarf', 'malzemeler', 'sarf', 'malzemeler', 'sarf', 'malzemeler', 'sarf', 'malzemeler', 'bebek', '075mm', '075mm', 'eco', 'termal', 'baskisiz', 'eti̇ket', 'şeffaf', 'ebebek', 'baskılı', '75x100', 'cm', 'sarf', 'malzemeler', 'sarf', 'malzemeler', 'sarf', 'malzemeler']\n",
      "corpus: [(2, 1), (5, 7), (8, 7), (10, 4), (11, 1), (12, 2), (13, 1), (14, 1), (15, 1), (16, 2), (17, 2), (18, 2), (19, 1)]\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "  print(25*\"*\" + f\" {i} \" + 25*\"*\")\n",
    "  print(f\"document: {df.final_tokenized[i]}\")\n",
    "  print(f\"corpus: {corpus[i]}\")\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center>Models</center></h2>\n",
    "<h3>TF-IDF Model</h3>\n",
    "  TF-IDF stands for term frequency - inverse document frequency. Term frequency means occurences of each words in a current document. Document frequency means occurences each word in whole document set. With the help these definitons we can express the TF-IDF score as follows:<br>\n",
    "\n",
    "  $$ tf idf (t, d, D) = tf(t, d) \\times \\log ({n \\over df(t)}) $$\n",
    "  \n",
    "<h3>LSI Model</h3>\n",
    "\n",
    "  The basic idea behind LSI is to take advantage of impli- cit higher-order structure in the association of terms with documents (‘‘semantic structure”) in order to improve the detection of relevant documents, on the basis of terms found in queries.<br>\n",
    "  LSI aims to find the best subspace approximation to the original document space in the sense of minimizing the global reconstruc- tion error (the difference of Frobenius norm between the original matrix and its approximation matrix). It is based on SVD (Singular Value Decomposition) and projects the document vectors into an approximated subspace, so that cosine similarity can accurately represent semantic similarity. (W. Zhang et al. / Expert Systems with Applications 38 (2011) 2758–2765)<br><br>\n",
    "  \n",
    "  Lets assume that A is a matrix that represents the tfidf scores of th terms. Than, if we apply SVD to the A matrix we can get result like on the below.\n",
    "  $$ A = TSD^T $$\n",
    "  Where T is the m by r term-concept vector matrix, S is the r by r singular values matrix, D is the n by r concept-document vector matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating TFIDF and LSI models \n",
    "ebebek_tfidf_model = gensim.models.TfidfModel(corpus, id2word=dictionary, smartirs=\"npu\")\n",
    "ebebek_lsi_model = gensim.models.LsiModel(ebebek_tfidf_model[corpus], id2word=dictionary, num_topics=900)\n",
    "\n",
    "# Saving model corpus\n",
    "gensim.corpora.MmCorpus.serialize('./models/tfidf/ebebek_tfidf_corpus', ebebek_tfidf_model[corpus])\n",
    "gensim.corpora.MmCorpus.serialize('./models/lsi/ebebek_lsi_corpus',ebebek_lsi_model[ebebek_tfidf_model[corpus]])\n",
    "\n",
    "# Saving TFIDF and LSI models\n",
    "ebebek_tfidf_model.save(\"./models/tfidf/ebebek_tfidf\")\n",
    "ebebek_lsi_model.save(\"./models/lsi/ebebek_lsi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebebek_tfidf_corpus = gensim.corpora.MmCorpus('./models/tfidf/ebebek_tfidf_corpus')\n",
    "ebebek_lsi_corpus = gensim.corpora.MmCorpus('./models/lsi/ebebek_lsi_corpus')\n",
    "\n",
    "malzeme_index = MatrixSimilarity(ebebek_lsi_corpus, num_features = ebebek_lsi_corpus.num_terms)\n",
    "malzeme_index.save(\"./models/malzeme_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'TF-IDF Scores'\n",
      "************************* 0 *************************\n",
      "[(0, 0.5851315519583672), (1, 1.1105291555344703), (2, 0.6407592953544803), (3, 1.7461007583504555), (4, 1.4491962501042694), (5, 1.3104070859882164), (6, 0.0327673502533431), (7, 1.155335354306532), (8, 1.3104070859882164)]\n",
      "************************* 1 *************************\n",
      "[(2, 0.6042884629225614), (5, 4.325373995156828), (8, 4.325373995156828), (9, 1.911041437869605), (10, 1.8444507475906713), (11, 0.7664361909564749), (12, 1.7052952185560455), (13, 0.24676303279393713), (15, 0.4196437096088453), (16, 1.3925312464125104), (17, 1.7605558623017357), (18, 1.0570252475665314), (19, 0.6152600004612219)]\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(\"TF-IDF Scores\")\n",
    "for i, token in enumerate(ebebek_tfidf_corpus):\n",
    "  print(25*\"*\" + f\" {i} \" + 25*\"*\")\n",
    "  print(token)\n",
    "  if i > 0:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'LSI Scores - 226263 X 1000'\n",
      "************************* 0 *************************\n",
      "[(0, 0.005497907040379719), (1, 0.01713535089712121), (2, 0.0003765940284761198), (3, 0.0027794364312258733), (4, 0.00700475856654261), (5, 0.010134953330622235), (6, -0.0017751325824238513), (7, 0.012523135802566018), (8, 0.0039051499052488565), (9, 0.007873681465036095)]\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(\"LSI Scores - 226263 X 1000\")\n",
    "for i, token in enumerate(ebebek_lsi_corpus):\n",
    "  print(25*\"*\" + f\" {i} \" + 25*\"*\")\n",
    "  print(token[:10])\n",
    "  if i > -1:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Matrix Similarity Results - 226263 X 226263'\n",
      "************************* 0 *************************\n",
      "[ 0.9999998   0.874396    0.8735253  ...  0.00638833 -0.00280114\n",
      " -0.00125104]\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(\"Matrix Similarity Results - 226263 X 226263\")\n",
    "for i, val in enumerate(malzeme_index):\n",
    "  print(25*\"*\" + f\" {i} \" + 25*\"*\")\n",
    "  print(val)\n",
    "  if i > -1:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(142022, 0.31501534581184387),\n",
       " (212071, 0.31501534581184387),\n",
       " (107907, 0.3147602081298828)]"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "malzeme_index.num_best = 3\n",
    "malzeme_index[[(0, .4), (1, .23)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5edc29c2ed010d6458d71a83433b383a96a8cbd3efe8531bc90c4b8a5b8bcec9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
